{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows the creation of the data sets from netcdf files of:\n",
    "\n",
    "* Agroclimatic Indicators: https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-agroclimatic-indicators?tab=overview)\n",
    "* Crop data for years 2005 and 2010: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/PRFF8V\n",
    "* Spatial data relevant to crops: These files need to be netcdf4 files that you want to add in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import rasterio\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from shared_methods import compute_ten_day_feature, compute_seasonal_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data folder structure from a stored json\n",
    "out_file = 'climate_monthly_seasonal_2005_2010_with_spatial_features.csv'\n",
    "\n",
    "with open('json_data/file_data.json', 'r') as outfile:\n",
    "    file_data = json.load(outfile)\n",
    "    \n",
    "seasonal_data_folder = file_data['seasonal_data_folder']\n",
    "ten_day_data_folder = file_data['ten_day_data_folder']\n",
    "crop_data_2005_file = file_data['crop_data_2005_file']\n",
    "crop_data_2010_file = file_data['crop_data_2010_file']\n",
    "spatial_attributes_folder = file_data['spatial_attributes_folder']\n",
    "ten_day_feature_files = file_data['ten_day_feature_files']\n",
    "seasonal_feature_files = file_data['seasonal_feature_files']\n",
    "spatial_attribute_files = file_data['spatial_attribute_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the crop data and clean it.\n",
    "# Choose the crop here\n",
    "crop = 'maize'\n",
    "\n",
    "# Read the crop data in\n",
    "crop_data_2005 = pd.read_csv(crop_data_2005_file,  encoding = \"ISO-8859-1\")\n",
    "crop_data_2010 = pd.read_csv(crop_data_2010_file,  encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Merge the data together on the 'alloc_key' wich refers to the same place on the Earth\n",
    "merged = crop_data_2010.merge(crop_data_2005, how='inner', on='alloc_key', suffixes=['_2010', '_2005'])\n",
    "\n",
    "# Only keep the columns we are interested in\n",
    "kept_columns = ['alloc_key', 'x', 'y', 'iso3_2010', f'{crop[0:4]}_a_2010', f'{crop[0:4]}_a_2005']\n",
    "merged = merged[kept_columns]\n",
    "\n",
    "\n",
    "# Rename the columns\n",
    "merged = merged.rename(columns={\n",
    "    f'{crop[0:4]}_a_2010': f'{crop}_a_2010',\n",
    "    f'{crop[0:4]}_a_2005': f'{crop}_a_2005',\n",
    "    'iso3_2010': 'iso3',\n",
    "    'x': 'lon',\n",
    "    'y': 'lat'\n",
    "})\n",
    "\n",
    "# Only include non zero and remove NaNs yields\n",
    "data = merged.dropna()\n",
    "data = data[data[f'{crop}_a_2005'] > 0]\n",
    "data = data[data[f'{crop}_a_2010'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the seasonal features        \n",
    "years = ['2010', '2009', '2006', '2005', '2004']\n",
    "seasonal_features = [\n",
    "    'CDD',\n",
    "    'CFD',\n",
    "    'CWD', \n",
    "    'WW',\n",
    "    'WSDI',\n",
    "    'CSDI'\n",
    "]\n",
    "\n",
    "for feature in tqdm(seasonal_features):\n",
    "    file_location = seasonal_data_folder + seasonal_feature_files[feature]\n",
    "    for year in years:\n",
    "        data = compute_seasonal_feature(feature, file_location, year, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the features you want on the top of the notebook based on the ten_day_feature_files\n",
    "# dict, and put them in this array.\n",
    "ten_day_features = ten_day_feature_files.keys()\n",
    "years = ['2010', '2009', '2006', '2005', '2004']\n",
    "    \n",
    "for feature in tqdm(ten_day_features):\n",
    "    file_location = ten_day_data_folder + ten_day_feature_files[feature]\n",
    "    for year in years:\n",
    "        data = compute_ten_day_feature(feature, file_location, year, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes bunches multiple years of data and creates a mean of the years. This is justified because the\n",
    "# crop data in this project is a mean over 1 year either side of the year in question.\n",
    "\n",
    "# For our project, there was no data for 2011 interim agriclimatic indicators, so a mean of 2009 and 2010 sufficed.\n",
    "year_bunches = [['2010', '2009'], ['2005', '2004', '2006']]\n",
    "features = fs = [col.replace('-2010', '') for col in data.columns if f'-2010' in col]\n",
    "for f in features:\n",
    "    for b in year_bunches:\n",
    "        data[f'{f}-{b[0]}'] = data[[f'{f}-{year}' for year in b]].mean(axis=1, skipna=True)\n",
    "        data = data.drop(columns=[f'{f}-{year}' for year in b[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spatial features for the data set. \n",
    "spatial_attributes = [\n",
    "    'soil_types',\n",
    "    'climate_zones',\n",
    "    'elevation',\n",
    "    'slope',\n",
    "    'irrigation'\n",
    "]\n",
    "\n",
    "categorical_spatial = [\n",
    "    'soil_types',\n",
    "    'climate_zones'\n",
    "]\n",
    "\n",
    "lats_ = xr.DataArray(list(data['lat'].values), dims='z')\n",
    "lons_ = xr.DataArray(list(data['lon'].values), dims='z')\n",
    "\n",
    "for feature in tqdm(spatial_attributes):\n",
    "    with xr.open_rasterio(spatial_attributes_folder + spatial_attribute_files[feature]) as ds:\n",
    "        feature_data = ds.load()\n",
    "    feature_data = feature_data.rename({'x': 'lon','y': 'lat'}).squeeze()\n",
    "    if feature in categorical_spatial:\n",
    "        # The categorical features must not be interpolated. We will have to stick to the nearest.\n",
    "        interpolation_method = 'nearest'\n",
    "    else:\n",
    "        interpolation_method = 'linear'\n",
    "    data[feature] = feature_data.interp(lat=lats_, lon=lons_, method=interpolation_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a csv\n",
    "data.to_csv(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
