{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file allows the creation of the data sets from netcdf files of:\n",
    "\n",
    "* Agroclimatic Indicators: https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-agroclimatic-indicators?tab=overview)\n",
    "* Crop data for years 2005 and 2010: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/PRFF8V\n",
    "* Spatial data relevant to crops: *** Need link for this ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm==4.42.1\n",
    "!pip install requests\n",
    "!pip install tabulate\n",
    "!pip install \"colorama>=0.3.8\"\n",
    "!pip install future\n",
    "!pip install netcdf4==1.5.3\n",
    "!pip install xarray\n",
    "!pip install numpy==1.18.1\n",
    "!pip install rasterio\n",
    "!pip install xgboost==0.90\n",
    "!pip install joblib==0.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import rasterio\n",
    "import pickle\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains the file information for the file names to load data in and save the created data set.\n",
    "\n",
    "# Add the locations of the data folders here, and the crop file locations\n",
    "seasonal_data_folder = '../data/seasonal_era_agriclimatic/'\n",
    "ten_day_data_folder = '../data/10-day-data/'\n",
    "crop_data_2005_file = '../data/spam2005v3r2_global_yield/spam2005V3r2_global_Y_TA.csv'\n",
    "crop_data_2010_file = '../data/spam2010v1r1_global_yield/spam2010V1r1_global_Y_TA.csv'\n",
    "\n",
    "# The crop data files are so named because that is their names on the Copernicus Website:\n",
    "# https://cds.climate.copernicus.eu/cdsapp#!/dataset/sis-agroclimatic-indicators?tab=overview\n",
    "\n",
    "ten_day_feature_files = {\n",
    "    'BEDD': 'BEDD_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'FD': 'FD_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'R20mm': 'R20mm_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'R10mm': 'R10mm_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'ID': 'ID_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TG': 'TG_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TN': 'TN_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'DTR': 'DTR_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'RR1': 'RR1_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'RR': 'RR_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'SDII': 'SDII_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'SU': 'SU_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TG': 'TG_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TNn': 'TNn_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TR': 'TR_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TX': 'TX_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TXn': 'TXn_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TXx': 'TXx_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc'\n",
    "}\n",
    "\n",
    "seasonal_feature_files = {\n",
    "    'CDD': 'CDD_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'CFD': 'CFD_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'CWD': 'CWD_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'WW': 'WW_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'WSDI': 'WSDI_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'CSDI': 'CSDI_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc'\n",
    "}\n",
    "\n",
    "spatial_attributes_folder = '../data/spatial_attributes_netcdf/'\n",
    "\n",
    "spatial_attribute_files = {\n",
    "    'soil_types': 'soil_types.nc',\n",
    "    'climate_zones': 'climate_zones.nc',\n",
    "    'slope': 'slope_resampled_percent.nc',\n",
    "    'elevation': 'elevation_resampled.nc',\n",
    "    'irrigation': 'irrigation_aei_rf.nc'\n",
    "}\n",
    "\n",
    "out_file = 'climate_monthly_seasonal_2005_2010_with_spatial_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the crop data and clean it.\n",
    "\n",
    "# Choose the crop here\n",
    "crop = 'maize'\n",
    "\n",
    "# Read the crop data in\n",
    "crop_data_2005 = pd.read_csv(crop_data_2005_file,  encoding = \"ISO-8859-1\")\n",
    "crop_data_2010 = pd.read_csv(crop_data_2010_file,  encoding = \"ISO-8859-1\")\n",
    "\n",
    "# Merge the data together on the 'alloc_key' wich refers to the same place on the Earth\n",
    "merged = crop_data_2010.merge(crop_data_2005, how='inner', on='alloc_key', suffixes=['_2010', '_2005'])\n",
    "\n",
    "# Only keep the columns we are interested in\n",
    "kept_columns = ['alloc_key', 'x', 'y', 'iso3_2010', f'{crop[0:4]}_a_2010', f'{crop[0:4]}_a_2005']\n",
    "merged = merged[kept_columns]\n",
    "\n",
    "\n",
    "# Rename the columns\n",
    "merged = merged.rename(columns={\n",
    "    f'{crop[0:4]}_a_2010': f'{crop}_a_2010',\n",
    "    f'{crop[0:4]}_a_2005': f'{crop}_a_2005',\n",
    "    'iso3_2010': 'iso3',\n",
    "    'x': 'lon',\n",
    "    'y': 'lat'\n",
    "})\n",
    "\n",
    "# Only include non zero and remove NaNs yields\n",
    "data = merged.dropna()\n",
    "data = data[data[f'{crop}_a_2005'] > 0]\n",
    "data = data[data[f'{crop}_a_2010'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 10 day features and converts them to monthly features\n",
    "def compute_ten_day_feature(feature, file_location, year, dataset, interpolation_method='linear'):\n",
    "    days = ['05', '15', '25']\n",
    "    months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "    lats_ = xr.DataArray(list(data['lat'].values), dims='z')\n",
    "    lons_ = xr.DataArray(list(data['lon'].values), dims='z')\n",
    "    with xr.open_dataset(file_location) as ds:\n",
    "        feature_data = ds.load()\n",
    "        for day in days:\n",
    "            for month in months:\n",
    "                time = f'{year}-{month}-{day}'\n",
    "                timed = feature_data.sel(time=time).squeeze()\n",
    "                feature_interpolated = timed.interp(lat=lats_, lon=lons_, method=interpolation_method)\n",
    "                dataset[f'{feature}-{month}-{day}-{year}'] = getattr(feature_interpolated, feature)\n",
    "    all_ten_days = []\n",
    "    \n",
    "    # This loop takes the sum of each feature for each month, making the features monthly as opposed to 10-day\n",
    "    for month in months:\n",
    "        for day in days:\n",
    "            all_ten_days.append(f'{feature}-{month}-{day}-{year}')\n",
    "            dataset[f'{feature}-{month}-{year}'] \\\n",
    "                = dataset[f'{feature}-{month}-05-{year}'] + dataset[f'{feature}-{month}-15-{year}'] + dataset[f'{feature}-{month}-25-{year}']\n",
    "    dataset = dataset.drop(columns=all_ten_days)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Computes the seasonal features.\n",
    "def compute_seasonal_feature(feature, file_location, year, dataset, interpolation_method='linear'):\n",
    "    lats = xr.DataArray(list(dataset['lat'].values), dims='z')\n",
    "    lons = xr.DataArray(list(dataset['lon'].values), dims='z')\n",
    "    quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    quarter_time_mapping = {\n",
    "        'Q1': '01-16',\n",
    "        'Q2': '04-16',\n",
    "        'Q3': '07-16',\n",
    "        'Q4': '10-16'\n",
    "    }\n",
    "    with xr.open_dataset(file_location) as ds:\n",
    "        feature_data = ds.load()\n",
    "        \n",
    "    for quarter in quarters:\n",
    "        feature_name = f'{feature}-{quarter}-{year}'\n",
    "        time = f'{year}-{quarter_time_mapping[quarter]}'\n",
    "        timed = feature_data.sel(time=time).squeeze()\n",
    "        feature_interpolated = timed.interp(lat=lats, lon=lons, method=interpolation_method)\n",
    "        dataset[feature_name] = getattr(feature_interpolated, feature)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the seasonal features        \n",
    "years = ['2010', '2009', '2006', '2005', '2004']\n",
    "seasonal_features = [\n",
    "    'CDD',\n",
    "    'CFD',\n",
    "    'CWD', \n",
    "    'WW',\n",
    "    'WSDI',\n",
    "    'CSDI'\n",
    "]\n",
    "\n",
    "for feature in tqdm(seasonal_features):\n",
    "    file_location = seasonal_data_folder + seasonal_feature_files[feature]\n",
    "    for year in years:\n",
    "        data = compute_seasonal_feature(feature, file_location, year, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the features you want on the top of the notebook based on the ten_day_feature_files\n",
    "# dict, and put them in this array.\n",
    "ten_day_features = ten_day_feature_files.keys()\n",
    "years = ['2010', '2009', '2006', '2005', '2004']\n",
    "    \n",
    "for feature in tqdm(ten_day_features):\n",
    "    file_location = ten_day_data_folder + ten_day_feature_files[feature]\n",
    "    for year in years:\n",
    "        data = compute_ten_day_feature(feature, file_location, year, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes bunches multiple years of data and creates a mean of the years. This is justified because the\n",
    "# crop data in this project is a mean over 1 year either side of the year in question.\n",
    "\n",
    "# For our project, there was no data for 2011 interim agriclimatic indicators, so a mean of 2009 and 2010 sufficed.\n",
    "year_bunches = [['2010', '2009'], ['2005', '2004', '2006']]\n",
    "features = fs = [col.replace('-2010', '') for col in data.columns if f'-2010' in col]\n",
    "for f in features:\n",
    "    for b in year_bunches:\n",
    "        data[f'{f}-{b[0]}'] = data[[f'{f}-{year}' for year in b]].mean(axis=1, skipna=True)\n",
    "        data = data.drop(columns=[f'{f}-{year}' for year in b[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spatial features for the data set. \n",
    "spatial_attributes = [\n",
    "    'soil_types',\n",
    "    'climate_zones',\n",
    "    'elevation',\n",
    "    'slope',\n",
    "    'irrigation'\n",
    "]\n",
    "\n",
    "categorical_spatial = [\n",
    "    'soil_types',\n",
    "    'climate_zones'\n",
    "]\n",
    "\n",
    "lats_ = xr.DataArray(list(data['lat'].values), dims='z')\n",
    "lons_ = xr.DataArray(list(data['lon'].values), dims='z')\n",
    "\n",
    "for feature in tqdm(spatial_attributes):\n",
    "    with xr.open_rasterio(spatial_attributes_folder + spatial_attribute_files[feature]) as ds:\n",
    "        feature_data = ds.load()\n",
    "    feature_data = feature_data.rename({'x': 'lon','y': 'lat'}).squeeze()\n",
    "    if feature in categorical_spatial:\n",
    "        # The categorical features must not be interpolated. We will have to stick to the nearest.\n",
    "        interpolation_method = 'nearest'\n",
    "    else:\n",
    "        interpolation_method = 'linear'\n",
    "    data[feature] = feature_data.interp(lat=lats_, lon=lons_, method=interpolation_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a csv\n",
    "data.to_csv(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
