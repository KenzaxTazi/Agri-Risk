{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import rasterio\n",
    "import pickle\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=10)\n",
    "\n",
    "ten_day_feature_files = {\n",
    "    'BEDD': 'BEDD_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'FD': 'FD_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'R20mm': 'R20mm_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'R10mm': 'R10mm_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'ID': 'ID_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TG': 'TG_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TN': 'TN_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'DTR': 'DTR_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'RR1': 'RR1_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'RR': 'RR_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'SDII': 'SDII_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'SU': 'SU_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TG': 'TG_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TNn': 'TNn_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TR': 'TR_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TX': 'TX_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TXn': 'TXn_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc',\n",
    "    'TXx': 'TXx_C3S-glob-agric_WFDEI_hist_dek_19810101-20101231_v1.nc'\n",
    "}\n",
    "\n",
    "seasonal_feature_files = {\n",
    "    'CDD': 'CDD_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'CFD': 'CFD_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'CWD': 'CWD_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'WW': 'WW_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'WSDI': 'WSDI_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc',\n",
    "    'CSDI': 'CSDI_C3S-glob-agric_WFDEI_hist_season_19810101-20101231_v1.nc'\n",
    "}\n",
    "\n",
    "# Compute the 10 day features\n",
    "def compute_ten_day_feature(feature, file_location, year, dataset, interpolation_method='linear', in_place_2010=False):\n",
    "    days = ['05', '15', '25']\n",
    "    months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "    lats_ = xr.DataArray(list(dataset['lat'].values), dims='z')\n",
    "    lons_ = xr.DataArray(list(dataset['lon'].values), dims='z')\n",
    "    with xr.open_dataset(file_location) as ds:\n",
    "        feature_data = ds.load()\n",
    "        for day in days:\n",
    "            for month in months:\n",
    "                time = f'{year}-{month}-{day}'\n",
    "                timed = feature_data.sel(time=time).squeeze()\n",
    "                feature_interpolated = timed.interp(lat=lats_, lon=lons_, method='linear')\n",
    "                dataset[f'{feature}-{month}-{day}-{year}'] = getattr(feature_interpolated, feature)\n",
    "    all_ten_days = []\n",
    "    for month in months:\n",
    "        for day in days:\n",
    "            all_ten_days.append(f'{feature}-{month}-{day}-{year}')\n",
    "        if in_place_2010:\n",
    "            feature_name = f'{feature}-{month}-2010'\n",
    "        else:\n",
    "            feature_name = f'{feature}-{month}-{year}'\n",
    "        dataset[feature_name] = dataset[f'{feature}-{month}-05-{year}'] + dataset[f'{feature}-{month}-15-{year}'] + dataset[f'{feature}-{month}-25-{year}']\n",
    "    dataset = dataset.drop(columns=all_ten_days)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def compute_seasonal_feature(feature, file_location, year, dataset, interpolation_method='linear', in_place_2010=False):\n",
    "    lats = xr.DataArray(list(dataset['lat'].values), dims='z')\n",
    "    lons = xr.DataArray(list(dataset['lon'].values), dims='z')\n",
    "    quarters = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    quarter_time_mapping = {\n",
    "        'Q1': '01-16',\n",
    "        'Q2': '04-16',\n",
    "        'Q3': '07-16',\n",
    "        'Q4': '10-16'\n",
    "    }\n",
    "    with xr.open_dataset(file_location) as ds:\n",
    "        feature_data = ds.load()\n",
    "        \n",
    "    for quarter in quarters:\n",
    "        if in_place_2010:\n",
    "            feature_name = f'{feature}-{quarter}-2010'\n",
    "        else:\n",
    "            feature_name = f'{feature}-{quarter}-{year}'\n",
    "        time = f'{year}-{quarter_time_mapping[quarter]}'\n",
    "        timed = feature_data.sel(time=time).squeeze()\n",
    "        feature_interpolated = timed.interp(lat=lats, lon=lons, method=interpolation_method)\n",
    "        dataset[feature_name] = getattr(feature_interpolated, feature)\n",
    "    return dataset\n",
    "\n",
    "def autograd_variable(input):\n",
    "    \"\"\" Convert input to a torch cuda or cpu tensor\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return autograd.Variable(input).cuda()\n",
    "    return autograd.Variable(input)\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, feature_count, dropout=0.05):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_count, 1000),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(autograd_variable(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                return self.forward(x.cuda())\n",
    "            else:\n",
    "                return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "degree_separation = 3\n",
    "lon_slices = int(360/degree_separation) + 1\n",
    "lon_range = np.linspace(-180,180,lon_slices)\n",
    "\n",
    "def select_bin(row):\n",
    "    for idx, edge in enumerate(lon_range[:-1]):\n",
    "        if row['lon'] > edge and row['lon'] < lon_range[idx + 1]:\n",
    "            return idx % 4\n",
    "\n",
    "final_data['bin'] = final_data.parallel_apply(select_bin, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in tqdm(final_data.columns):\n",
    "    if '-2005' in f:\n",
    "        feature = f.replace('-2005', '')\n",
    "        final_data[f'delta-{feature}'] = final_data[f'{feature}-2010'] - final_data[f]\n",
    "        final_data = final_data.drop(columns=[f'{feature}-2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regressors.pickle', 'rb') as handle:\n",
    "    regressors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('deltas.csv')\n",
    "prediction_features = [f for f in final_data.columns if 'delta' in f] + ['lon', 'lat', 'slope', 'irrigation', 'elevation', 'climate_zones', 'soil_types', 'maize_a_2005']\n",
    "prediction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin_idx in range(4):\n",
    "    with open(f'regressors_{bin_idx}.pickle', 'rb') as handle:\n",
    "        regressor = pickle.load(handle)\n",
    "    test_bin = ((bin_idx + 2) % 4)\n",
    "    test_data = final_data[final_data['bin'] == test_bin]\n",
    "    test_data['prediction'] = regressor.predict(test_data[prediction_features])\n",
    "    test_data[['prediction', 'maize_a_2010']].to_csv(f'test_data_predictions_{bin_idx}')\n",
    "    del regressor\n",
    "#     regressors[train_bin] = regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('regressors.pickle', 'rb') as handle:\n",
    "    regressors = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "prediction_features_counts = defaultdict(lambda: 0.0)\n",
    "for k,r in regressors.items():\n",
    "     for x in zip(r.feature_importances_, prediction_features):\n",
    "          prediction_features_counts[x[1]] += x[0]/4.0\n",
    "        \n",
    "sorted([(v, k) for k,v in prediction_features_counts.items()], reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bin_, regressor in regressors.items():\n",
    "    with open(f'regressors_{bin_}.pickle', 'wb') as handle:\n",
    "        pickle.dump(regressor, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop(columns=[c for c in final_data.columns if '-2010' in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_features = [f for f in final_data.columns if 'delta' in f] + ['lon', 'lat', 'slope', 'irrigation', 'elevation', 'climate_zones', 'soil_types', 'maize_a_2005']\n",
    "prediction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_years = [2019, 2020, 2021, 2024, 2025, 2026, 2039, 2040, 2042]\n",
    "rcps = ['2p6', '4p5', '6p0', '8p5']\n",
    "out_file = f'../data/hadgem_predictions_year_{prediction_years}_final.csv'  # load data\n",
    "model = 'hadgem'\n",
    "\n",
    "# Predict for different years\n",
    "# def compute_features_for_rcp(rcp, final_data=final_data[['lon', 'lat', 'slope', 'irrigation', 'elevation', 'climate_zones', 'soil_types', 'maize_a_2005']]):\n",
    "for rcp in rcps:\n",
    "    folder = f'../data/{model}/{model}_rcp_{rcp}_agroclimatic_indicators/'\n",
    "    for year in tqdm(prediction_years):\n",
    "        print(f'Starting Model: {model} Year {year} RCP {rcp}')\n",
    "        if int(year) in range(2011,2041):\n",
    "            file_ending = '20110101-20401231_v1.nc'\n",
    "        elif int(year) in range(2041,2071):\n",
    "            file_ending = '20410101-20701231_v1.nc'\n",
    "\n",
    "        for feature in tqdm(seasonal_feature_files.keys()):\n",
    "            file_location = f'{folder}{feature}_C3S-glob-agric_hadgem2-es_rcp{rcp}_season_{file_ending}'\n",
    "            final_data = compute_seasonal_feature(feature, file_location, str(year), final_data, in_place_2010=True)\n",
    "\n",
    "        for feature in tqdm(ten_day_feature_files.keys()):    \n",
    "            file_location = f'{folder}{feature}_C3S-glob-agric_hadgem2-es_rcp{rcp}_dek_{file_ending}'\n",
    "            final_data = compute_ten_day_feature(feature, file_location, str(year), final_data, in_place_2010=True)\n",
    "#             final_data.to_csv(f'../data/{model}/precomputed_{model}_year_{year}_rcp_{rcp}.csv')\n",
    "        final_data = final_data.interpolate(axis=1)\n",
    "        for f in tqdm(final_data.columns):\n",
    "            if '-2005' in f:\n",
    "                feature = f.replace('-2005', '')\n",
    "                final_data[f'delta-{feature}'] = final_data[f'{feature}-2010'] - final_data[f]\n",
    "                final_data = final_data.drop(columns=[f'{feature}-2010'])\n",
    "\n",
    "        final_data[f'{rcp}_{year}_predict'] = 0\n",
    "        for bin_ in [0, 1, 2, 3]:\n",
    "            with open(f'regressors_{bin_}.pickle', 'rb') as handle:\n",
    "                regressor = pickle.load(handle)\n",
    "            final_data.loc[final_data['bin'] ==  bin_, f'{rcp}_{year}_predict'] = regressor.predict(final_data[final_data['bin'] ==  bin_][prediction_features])\n",
    "            del regressor\n",
    "        print(f'Finished year {year} rcp {rcp} model {model}')\n",
    "    \n",
    "\n",
    "final_data.to_csv('predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[[c for c in final_data.columns if 'pred' in c] + ['maize_a_2010', 'lon', 'lat', 'alloc_key']].to_csv('final_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final_data[[c for c in final_data.columns if 'pred' in c] + ['maize_a_2010', 'lon', 'lat', 'alloc_key']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_years = [2040, 2025, 2020]\n",
    "for year in tqdm(prediction_years):\n",
    "    mean_included_years = [str(year), str(year + 1), str(year - 1)]\n",
    "    if year == 2040:\n",
    "        mean_included_years = [str(year), str(year + 2), str(year - 1)]\n",
    "    mean_included_year_columns = []\n",
    "    for rcp in rcps:\n",
    "        mean_included_year_columns += [f'{rcp}_{col}_predict' for col in mean_included_years]\n",
    "    predictions[f'{year}_mean'] = predictions[mean_included_year_columns].mean(axis=1)\n",
    "    predictions[f'{year}_std'] = predictions[mean_included_year_columns].std(axis=1)\n",
    "                                          \n",
    "\n",
    "predictions.to_csv(f'Predictions for Years: {prediction_years}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
