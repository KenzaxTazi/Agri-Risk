{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KenzaxTazi/Agri-Risk/blob/master/RFECV_damons_way_Raghul_for_Mala.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Selection\n",
    "This Notebook describes how to run recursive feature selection with k-folds cross validation on a data set.\n",
    "This was used to reduce the number of features used in the training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhNDZx7rLgeg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection\n",
    "import time\n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters for the notebook\n",
    "random_state = 42\n",
    "\n",
    "n_samples = 50000\n",
    "number_of_features = 150\n",
    "target = 'maize_a_2010'\n",
    "\n",
    "XGBoost_max_depth = 8\n",
    "XGBoost_min_child_weight = 20\n",
    "n_estimators = 80\n",
    "objective = 'reg:squarederror'\n",
    "tree_method = 'gpu_hist'\n",
    "gamma = 1\n",
    "error_score = 'raise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SD_3SpXhLlFv"
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('/content/drive/My Drive/Team Plants/data/climate_monthly_seasonal_2005_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HS110VYNqy4"
   },
   "outputs": [],
   "source": [
    "# Interpolate NaNs away and sample the data set (the full data set caused time and memory issues)\n",
    "df = df.sort_values(by=['lon'])\n",
    "df = df.interpolate(axis=1)\n",
    "df = df.sample(n_samples, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features and corresponding target\n",
    "X = df.drop([target], axis=1)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mXqsP-r2NItY",
    "outputId": "dbc10ce2-010c-4660-e12b-7ffc320dd63d"
   },
   "outputs": [],
   "source": [
    "# Create the Pipeline and fit the feature selector\n",
    "class PipelineRFE(Pipeline):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self\n",
    "\n",
    "pipe = PipelineRFE([(\"RF\", xgb.XGBRegressor(tree_method=tree_method,\n",
    "                                            objective=objective,\n",
    "                                            random_state=random_state,\n",
    "                                            error_score=error_score,\n",
    "                                            gamma=gamma,\n",
    "                                            max_depth=XGBoost_max_depth,\n",
    "                                            min_child_weight=XGBoost_min_child_weight,\n",
    "                                            n_estimators=n_estimators))])\n",
    "     \n",
    "kfolds = KFold(n_splits=4, random_state=42, shuffle=False)\n",
    "feature_selector_cv = feature_selection.RFECV(pipe, cv=kfolds, step=1, scoring=\"neg_mean_squared_error\",verbose=3)\n",
    "feature_selector_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "OgH2I_4NOcol",
    "outputId": "f5bb831e-02fc-4ca4-df87-f9bf77d2621e"
   },
   "outputs": [],
   "source": [
    "# Plot the RMSE as a function of the number of features\n",
    "cv_grid_rmse = np.sqrt(-feature_selector_cv.grid_scores_)\n",
    "\n",
    "plt.plot(cv_grid_rmse)\n",
    "plt.title('RMSE versus number of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the analysing the graph and computational considerations, decide on a number of features\n",
    "selected_features = [f for f, r in zip(X.columns, feature_selector_cv.ranking_) if r < number_of_features]\n",
    "print(selected_features)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "RFECV_damons_way_Raghul_for_Mala.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
