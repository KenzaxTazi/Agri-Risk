{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training\n",
    "This Notebook contains the code to train a Neural Network on the crop data.\n",
    "\n",
    "The parameters in the model below are the one's that were decided upon after a parameter search. It should be noted though that compared to the ensemble methods, the NNs have a much larger search space over relevant parameters.\n",
    "\n",
    "The Neural Network is restricted to the same amount of nodes in each hidden layer to reduce parameter search needed.\n",
    "\n",
    "This code is simplified from original the script used, which had to iterate through validation sets, using the degree splitting technique. To simplify, this code only splits the data into training and test sets, and only trains one model.\n",
    "\n",
    "The final model used in the predictions for the project was the Random Forest. Given more time, an exhaustive hyper parameter search would have been used to identify the best NN architecture more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the training run. All non target and non categorical columns will be features\n",
    "# will be normalized.\n",
    "target = 'maize_a_2010'\n",
    "categorical_features = ['soil_types', 'climate_zones']\n",
    "read_file_path = 'data_set.csv'\n",
    "\n",
    "# NN parameters\n",
    "test_size = 0.2\n",
    "adam_epsilon = 1.5e-4\n",
    "lr = 0.00001\n",
    "batch_size = 64\n",
    "dropout = 0.05\n",
    "layer_size = 1000\n",
    "training_step_iteration = 1000\n",
    "max_training_steps = 100000\n",
    "optimizer = torch.optim.Adam\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data in to pandas\n",
    "data = pd.read_csv(read_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autograd_variable(input):\n",
    "    \"\"\" Convert input to a torch cuda or cpu tensor\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return autograd.Variable(input).cuda()\n",
    "    return autograd.Variable(input)\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, feature_count, dropout=dropout):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_count, layer_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_size, layer_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_size, layer_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_size, layer_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_size, layer_size),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_size, 1),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(autograd_variable(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            if torch.cuda.is_available():\n",
    "                return self.forward(x.cuda())\n",
    "            else:\n",
    "                return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode categorical features\n",
    "yields = data[[target]]\n",
    "continuous_features_not_transformed = data.drop(columns=[target] + categorical_features)\n",
    "scaled_columns = list(features_not_transformed.columns)\n",
    "\n",
    "soil_dummies = pd.get_dummies(data.soil_types)\n",
    "climate_zone_dummies = pd.get_dummies(data.climate_zones)\n",
    "data_with_encoded_categorical_data = pd.concat([features_not_transformed, soil_dummies, climate_zone_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_with_encoded_categorical_data, yields, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the continuous data\n",
    "scaler_feature = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "target_data = scaler_target.fit_transform(y_train)\n",
    "train_feature_data = np.concatenate([scaler_feature.fit_transform(X_train[scaled_columns]), X_train.drop(columns=scaled_columns).values], axis=1)\n",
    "test_feature_data = np.concatenate([scaler_feature.transform(X_test[scaled_columns]), X_test.drop(columns=scaled_columns).values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "live_model = NN(feature_data.shape[1], dropout=dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "optimizer = optimizer(live_model.parameters(), lr=lr)\n",
    "\n",
    "for i in range(max_training_steps):\n",
    "    random_indices = np.random.randint(n, size=batch_size)\n",
    "    target = torch.FloatTensor(target_data[random_indices, :])\n",
    "    features = torch.FloatTensor(train_feature_data[random_indices, :])\n",
    "    prediction = live_model.forward(autograd_variable(features))\n",
    "    loss = loss_func(prediction, autograd_variable(target))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % training_step_iteration == 0:\n",
    "        with torch.no_grad():\n",
    "            test_prediction = live_model.predict(torch.FloatTensor(test_feature_data)).cpu()\n",
    "            train_prediction = live_model.predict(torch.FloatTensor(train_feature_data)).cpu()\n",
    "        \n",
    "        train_yield_predicted = scaler_target.inverse_transform(train_prediction)\n",
    "        test_yield_predicted = scaler_target.inverse_transform(test_prediction)\n",
    "        print('Test Set R2 Score',\n",
    "              r2_score(y_test, test_yield_predicted),\n",
    "              'Train Set R2 Score',\n",
    "              r2_score(y_train, train_yield_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters\n",
    "torch.save(live_model.state_dict(), 'model_params')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
